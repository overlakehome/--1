##### Hadoop - [ [Ubuntu](http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-single-node-cluster/) | [Mac OS X](http://wiki.apache.org/hadoop/Running_Hadoop_On_OS_X_10.5_64-bit_\(Single-Node_Cluster\)) ]

* `brew install hadoop`
* Setup [passphraseless ssh](http://hadoop.apache.org/docs/stable/single_node_setup.html#Setup+passphraseless)
  * `ssh-keygen -t rsa`, and then `cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys`
* Setup `/usr/local/Cellar/hadoop/1.1.2/libexec/conf/hadoop-env.sh`
  * `export JAVA_HOME=/System/Library/Frameworks/JavaVM.framework/Versions/CurrentJDK/Home`
  * `export HADOOP_OPTS="-Djava.security.krb5.realm= -Djava.security.krb5.kdc="`
* Setup pseudo-distributed operation http://hadoop.apache.org/docs/stable/single_node_setup.html#PseudoDistributed
* Bring up the [name node](http://localhost:50070/) and [job tracker](http://localhost:50030/)

```bash
hadoop namenode -format
start-all.sh # starts hadoop daemons along w/ the name node and job tracker
ps aux | grep hadoop | grep -v grep | wc -l # puts '5'
hadoop jar /usr/local/Cellar/hadoop/1.1.2/libexec/hadoop-examples-1.1.2.jar pi 10 100 # computes pi
stop-all.sh # stops hadoop daemons.
```

* [Yahoo Dev. Network - Hadoop Tutorial](http://developer.yahoo.com/hadoop/tutorial/)
* [HDFS and Map Reduce Introduction](http://www.thegeekstuff.com/2012/01/hadoop-hdfs-mapreduce-intro/)

##### Mahout Trunk

* `svn checkout http://svn.apache.org/repos/asf/mahout/trunk /workspace/mahout-trunk`

##### Mahout 0.7

```bah
curl -o ~/Downloads/mahout-distribution-0.7.zip -kL http://www.globalish.com/am/mahout/0.7/mahout-distribution-0.7.zip
unzip -o ~/Downloads/mahout-distribution-0.7.zip -d /workspace/
ln -s /workspace/mahout-distribution-0.7 /workspace/mahout
```

##### Mahout Demo w/ 21,578 documents taking 2 hours.

###### Prepare Sequence Files

```bash
MAHOUT="/workspace/mahout/bin/mahout" # which mahout
HADOOP="/usr/local/bin/hadoop" # which hadoop

WORK_DIR=/tmp/mahout-work-${USER}
mkdir -p ${WORK_DIR}
```

* `WARN: driver.MahoutDriver: [No org.apache.lucene.benchmark.utils.ExtractReuters.props found on classpath](http://lucene.apache.org/core/4_4_0/benchmark/org/apache/lucene/benchmark/utils/ExtractReuters.html)`

```bash
if [ ! -e ${WORK_DIR}/reuters-out ]; then
    if [ ! -e ${WORK_DIR}/reuters-sgm ]; then
        if [ ! -f ${WORK_DIR}/reuters21578.tar.gz ]; then
            echo "Downloading Reuters-21578"
            curl http://kdd.ics.uci.edu/databases/reuters21578/reuters21578.tar.gz -o ${WORK_DIR}/reuters21578.tar.gz
        fi
        mkdir -p ${WORK_DIR}/reuters-sgm
        echo "Extracting..."
        tar xzf ${WORK_DIR}/reuters21578.tar.gz -C ${WORK_DIR}/reuters-sgm
    fi
    echo "Extracting Reuters"
    $MAHOUT org.apache.lucene.benchmark.utils.ExtractReuters ${WORK_DIR}/reuters-sgm ${WORK_DIR}/reuters-out

    echo "Copying Reuters data to Hadoop"
    $HADOOP dfs -rmr ${WORK_DIR}/reuters-sgm || true
    $HADOOP dfs -rmr ${WORK_DIR}/reuters-out || true
    $HADOOP dfs -put ${WORK_DIR}/reuters-sgm ${WORK_DIR}/reuters-sgm
    $HADOOP dfs -put ${WORK_DIR}/reuters-out ${WORK_DIR}/reuters-out
    
    echo "Converting to Sequence Files"
    $MAHOUT seqdirectory -i ${WORK_DIR}/reuters-out -o ${WORK_DIR}/reuters-out-seqdir -ow -c UTF-8 -chunk 5
fi
```

###### LDA and ...

```bash
$MAHOUT seq2sparse \
  -i ${WORK_DIR}/reuters-out-seqdir/ \
  -o ${WORK_DIR}/reuters-out-seqdir-sparse-lda -ow --maxDFPercent 85 --namedVector \
&& \
$MAHOUT rowid \
  -i ${WORK_DIR}/reuters-out-seqdir-sparse-lda/tfidf-vectors \
  -o ${WORK_DIR}/reuters-out-matrix \
&& \
rm -rf ${WORK_DIR}/reuters-lda ${WORK_DIR}/reuters-lda-topics ${WORK_DIR}/reuters-lda-model \
&& \
$MAHOUT cvb \
  -i ${WORK_DIR}/reuters-out-matrix/matrix \
  -o ${WORK_DIR}/reuters-lda -k 20 -ow -x 20 \
  -dict ${WORK_DIR}/reuters-out-seqdir-sparse-lda/dictionary.file-* \
  -dt ${WORK_DIR}/reuters-lda-topics \
  -mt ${WORK_DIR}/reuters-lda-model \
&& \
$MAHOUT vectordump \
  -i ${WORK_DIR}/reuters-lda-topics/part-m-00000 \
  -o ${WORK_DIR}/reuters-lda/vectordump \
  -vs 10 -p true \
  -d ${WORK_DIR}/reuters-out-seqdir-sparse-lda/dictionary.file-* \
  -dt sequencefile -sort ${WORK_DIR}/reuters-lda-topics/part-m-00000 \
  && \
cat ${WORK_DIR}/reuters-lda/vectordump
```

* reuters-out-seqdir-sparse-lda
  * df-count
  * dictionary.file-0
  * frequency.file-0
  * tf-vectors
  * tfidf-vectors
  * tokenized-documents
  * wordcount
* reuters-out-matrix
  * docIndex
  * matrix
* reuters-lda-model
* reuters-lda-topic

##### Mahout LDA

```bash
hadoop dfs -rmr /tmp/dfs0 /tmp/dfs1 /tmp/dfs2 /tmp/dfs3 /tmp/dfs4
hadoop dfs -put /tmp/local0 /tmp/dfs0
mahout seqdirectory -i /tmp/dfs0/ -o /tmp/dfs1/ -ow # -c UTF-8
mahout seq2sparse -i /tmp/dfs1/ -o /tmp/dfs2/ -ow -wt tf # -seq -ng 3 -nr 3 -ml 20 # ngram(3), reducer(3), minLLR(20)
mahout lda -i /tmp/dfs2/tf-vectors/ -o /tmp/dfs3/ -k 12 -v 32768 # -a 20
mahout cvb -i /tmp/dfs2/tf-vectors/ -o /tmp/dfs3/ -ow -k 12 -nt 32768 -x 10000
```

* LDA CVB?
  * http://stackoverflow.com/questions/16994529/how-to-print-mahout-lda-cvb-topic
  * http://stackoverflow.com/questions/17119703/what-is-represented-by-the-doc-topic-distribution-output-of-mahouts-cvb-imple
  * http://stackoverflow.com/questions/11651713/using-mahout-to-train-an-lda-and-retrieve-its-topics

##### Install [Eclipse Kepler (4.3)](http://www.eclipse.org/downloads/)

```bash
curl -o ~/Downloads/eclipse-standard-kepler-R-macosx-cocoa-x86_64.tar.gz -kL http://ftp.osuosl.org/pub/eclipse/technology/epp/downloads/release/kepler/R/eclipse-standard-kepler-R-macosx-cocoa-x86_64.tar.gz
tar xvf ~/Downloads/eclipse-standard-kepler-R-macosx-cocoa-x86_64.tar.gz -C /Applications/
open /Applications/eclipse/Eclipse.app # and then keep this in dock
```

#### text app in java

```bash
echo | mvn archetype:generate \
  -DarchetypeGroupId=org.apache.maven.archetypes \
  -DarchetypeArtifactId=maven-archetype-quickstart \
  -DarchetypeVersion=1.1 \
  -DgroupId=com.henry4j \
  -DartifactId=text \
  -Dversion=1.0-SNAPSHOT \
  -DpackageName=com.henry4j \
  -DinteractiveMode=false
```

* add dependencies to pom.xml
  * [google-guava-14.0.1.jar](http://search.maven.org/#artifactdetails%7Ccom.google.guava%7Cguava%7C14.0.1%7Cbundle)
  * [opencsv-2.3.jar](http://search.maven.org/#artifactdetails%7Cnet.sf.opencsv%7Copencsv%7C2.3%7Cjar)
  * [porter-stemmer-1.4.jar](http://search.maven.org/#artifactdetails%7Cgov.sandia.foundry%7Cporter-stemmer%7C1.4%7Cjar)

* `mvn eclipse:eclipse -DdownloadSources=true`

eod
